## üìë Tabla de Contenido

- [üöÄ Instrucciones para Ejecutar el Proyecto](#-instrucciones-para-ejecutar-el-proyecto)
  - [Requisitos Previos](#requisitos-previos)
  - [Pasos para Ejecutar](#pasos-para-ejecutar)
  - [üîó Probar las APIs](#-probar-las-apis)
    - [1. **Actualizar registros en Mongo desde el archivo  cargado**](#1-actualizar-registros-en-mongo-desde-el-archivo--cargado)
      - [üìÅ Archivos de ejemplo](#-archivos-de-ejemplo)
      - [üîß Par√°metros opcionales:](#-par√°metros-opcionales)
    - [2. üìä **Entrar al GUI de Mongo para visualizar datos**](#2--entrar-al-gui-de-mongo-para-visualizar-datos)
    - [3 üåê **Endpoints Disponibles en la aplicacion MELI API**](#3--endpoints-disponibles-en-la-aplicacion-meli-api)
    - [üîπ `/items` - Consulta de √çtems](#-items---consulta-de-√≠tems)
    - [üîπ `/categories` - Consulta de Categor√≠as](#-categories---consulta-de-categor√≠as)
    - [üîπ `/currencies` - Consulta de Monedas](#-currencies---consulta-de-monedas)
    - [Soluciones del ejercicio propuesto](#soluciones-del-ejercicio-propuesto)
      - [Solucion A:](#solucion-a)
      - [üîó Diagrama de Componentes](#-diagrama-de-componentes)
      - [üîÑ Diagrama de Estados](#-diagrama-de-estados)
      - [Solucion B:](#solucion-b)
      - [üîó Diagrama de Componentes](#-diagrama-de-componentes-1)
      - [üîÑ Diagrama de Secuencia](#-diagrama-de-secuencia)
    - [üöÄ Mejoras a implementar](#-mejoras-a-implementar)
    - [‚öôÔ∏è Arquitectura y Dise√±o](#Ô∏è-arquitectura-y-dise√±o)
    - [üìÅ Estructura del C√≥digo](#-estructura-del-c√≥digo)
- [üìò Desaf√≠o Te√≥rico](#-desaf√≠o-te√≥rico)
  - [1. Procesos, hilos y corrutinas](#1-procesos-hilos-y-corrutinas)
    - [‚óè Un caso en el que usar√≠as procesos para resolver un problema y por qu√©](#-un-caso-en-el-que-usar√≠as-procesos-para-resolver-un-problema-y-por-qu√©)
    - [‚óè Un caso en el que usar√≠as threads para resolver un problema y por qu√©](#-un-caso-en-el-que-usar√≠as-threads-para-resolver-un-problema-y-por-qu√©)
    - [‚óè Un caso en el que usar√≠as corrutinas para resolver un problema y por qu√©](#-un-caso-en-el-que-usar√≠as-corrutinas-para-resolver-un-problema-y-por-qu√©)
  - [2. Optimizaci√≥n de recursos del sistema operativo](#2-optimizaci√≥n-de-recursos-del-sistema-operativo)
    - [‚óè Si tuvieras 1.000.000 de elementos y tuvieras que consultar para cada uno de ellos informaci√≥n en una API HTTP. ¬øC√≥mo lo har√≠as? Explicar.](#-si-tuvieras-1000000-de-elementos-y-tuvieras-que-consultar-para-cada-uno-de-ellos-informaci√≥n-en-una-api-http-c√≥mo-lo-har√≠as-explicar)
  - [3. An√°lisis de complejidad](#3-an√°lisis-de-complejidad)
    - [‚óè Dados 4 algoritmos A, B, C y D que cumplen la misma funcionalidad, con complejidades O(n¬≤), O(n¬≥), O(2‚Åø) y O(n log n), respectivamente, ¬øCu√°l de los algoritmos favorecer√≠as y cu√°l descartar√≠as en principio? Explicar por qu√©.](#-dados-4-algoritmos-a-b-c-y-d-que-cumplen-la-misma-funcionalidad-con-complejidades-on-on-o2‚Åø-y-on-log-n-respectivamente-cu√°l-de-los-algoritmos-favorecer√≠as-y-cu√°l-descartar√≠as-en-principio-explicar-por-qu√©)
    - [‚óè Asume que dispones de dos bases de datos para utilizar en diferentes problemas a resolver. La primera, llamada AlfaDB, tiene una complejidad de O(1) en consulta y O(n¬≤) en escritura. La segunda, llamada BetaDB, tiene una complejidad de O(log n) tanto para consulta como para escritura. Describe, en forma sucinta, qu√© casos de uso podr√≠as atacar con cada una.](#-asume-que-dispones-de-dos-bases-de-datos-para-utilizar-en-diferentes-problemas-a-resolver-la-primera-llamada-alfadb-tiene-una-complejidad-de-o1-en-consulta-y-on-en-escritura-la-segunda-llamada-betadb-tiene-una-complejidad-de-olog-n-tanto-para-consulta-como-para-escritura-describe-en-forma-sucinta-qu√©-casos-de-uso-podr√≠as-atacar-con-cada-una)



# üöÄ Instrucciones para Ejecutar el Proyecto

Este proyecto utiliza Docker para levantar dos APIs en Flask y una base de datos MongoDB junto con mongo-express, una interfaz web para explorar los datos de Mongo. Sigue estos pasos para correrlo desde cero:

## Requisitos Previos

- Tener instalado Docker y Docker Compose.

## Pasos para Ejecutar

1. **Clonar el repositorio**

```bash
git clone https://github.com/JassonM0lina/technical_challenge_meli
cd technical_challenge_meli
```

2. **Levantar los contenedores**

```bash
docker-compose  -f docker-compose.yaml up --build
```

Esto construir√° y levantar√° los siguientes servicios:

- üêç **meli_api** (puerto `5000`): API para consultar informaci√≥n de productos en Mercado Libre
- üß™ **integration_api** (puerto `5001`): API para actualizar la base de datos en MongoDB. 
- üçÉ **MongoDB** (puerto `27017`): Base de datos que almacena la informaci√≥n.
- üìä **mongo-express** (puerto `8081`): Interfaz web para visualizar los datos en Mongo.

> **Usuario/Contrase√±a para mongo-express:** `admin` / `admin`


3. **Verificar el estado de los servicios**
   Puedes usar el siguiente comando para ver los logs y verificar que todo est√° corriendo correctamente:

```bash
docker-compose logs -f
```

4. **Detener los servicios**

```bash
docker-compose  -f docker-compose.yaml down v 
```
## üîó Probar las APIs

Una vez los servicios est√©n corriendo, puedes probar las APIs con `curl` o Postman.


### 1. **Actualizar registros en Mongo desde el archivo  cargado**

```bash
POST: http://localhost:5001/update
```

Body JSON:
```json
{
  "name_file": "datalake.csv",
  "format": "csv",
  "separator": ",",
  "encoding": "utf-8"
}
```
#### üìÅ Archivos de ejemplo

En la carpeta `./integration_api/fetch_integrate/domain/assets` se encuentran **cuatro archivos** que contienen la misma informaci√≥n de los campos `"site"` e `"id"` de los √≠tems:

- `datalake.csv`: formato **`csv`**, separador **`,`**
- `datalake_semicolon.csv`: formato **`csv`**, separador **`;`**
- `datalake.txt`: formato **`txt`**, separador **`,`**
- `datalake.jsonl`: formato **`jsonl`**

> üìå Si desea probar un nuevo archivo, por favor ub√≠quelo en la misma carpeta:  
> `./integration_api/fetch_integrate/domain/assets`


#### üîß Par√°metros opcionales:

- `register_attributes`: lista de atributos que deseas guardar en Mongo. Si no se especifica, el valor por defecto es:
  ```json
  ["price", "name", "description"]
  ```
  - Si se agrega un atributo que no est√° soportado, se insertar√° como `null` en Mongo y se almacenar√° en la colecci√≥n `incomplete_register`.
  - Si se omite alguno de los atributos por defecto, el registro estar√° en `complete_register` pero sin ese atributo.
  - Los √∫nicos atributos que **siempre** estar√°n presentes son `id` y `site`.

- `len_batch`: n√∫mero de elementos que se procesar√°n por cada solicitud a la API de MELI. Valor por defecto: `50`.
  - Se ajust√≥ este par√°metro para evitar superar el l√≠mite de caracteres en peticiones HTTP (usualmente no m√°s de 2000 caracteres por GET).

  Body JSON con par√°materos opcionales:

```json
{
  "register_attributes": ["price", "name", "description"],
  "len_batch": 50,
  "name_file": "datalake.csv",
  "format": "csv",
  "separator": ",",
  "encoding": "utf-8"
}
```

---
### 2. üìä **Entrar al GUI de Mongo para visualizar datos**

```bash
http://localhost:8081/
```

Una vez se haya hecho el POST a http://localhost:5001/update, se puede ingresar a http://localhost:8081/, que corresponde al servicio de Mongo Express, y all√≠ podr√° visualizar la informaci√≥n cargada en la base de datos de MongoDB.

![Mongo Express](./assets/mongo_express.png)

---

### 3 üåê **Endpoints Disponibles en la aplicacion MELI API**

La aplicaci√≥n expone tres endpoints HTTP `GET` para consultar informaci√≥n directamente desde la API de Mercado Libre seg√∫n el tipo de entidad: √≠tems, categor√≠as o monedas.

### üîπ `/items` - Consulta de √çtems

Este endpoint permite consultar m√∫ltiples √≠tems de Mercado Libre junto con los atributos deseados. Este endpoint simula el API de mercado libre y la data se guarda como `meli_items_data.json`.

```bash
GET: http://localhost:5000/items
URL_EJEMPLO = /items?ids=MLA750925229,MLA845041373,MLA693105237&attributes=id,title,price
```

**Par√°metros:**
- `ids` (requerido): lista separada por comas de IDs de productos de Mercado Libre.
- `attributes` (opcional): lista separada por comas de atributos espec√≠ficos que deseas obtener por cada √≠tem (ej. `id`, `title`, `price`, `description`, etc.).

**Respuesta:**  
Un JSON con los datos solicitados para cada √≠tem.  


### üîπ `/categories` - Consulta de Categor√≠as

Este endpoint permite obtener informaci√≥n de las categor√≠as de productos. Este endpoint simula el API de mercado libre y la data se guarda como `meli_categories_data.json`.

```bash
GET: http://localhost:5000/categories
URL_EJEMPLO = http://localhost:5000/categories?ids=CAT275
```

**Par√°metros:**
- `ids` (requerido): ID de la categor√≠a de Mercado Libre.

**Respuesta:**  
Un JSON con los datos de la categor√≠a correspondiente.  

### üîπ `/currencies` - Consulta de Monedas


```bash
GET: http://localhost:5000/currencies
URL_EJEMPLO = http://localhost:5000/currencies?ids=CUR462
```
**Par√°metros:**
- `ids` (requerido): ID de la moneda que deseas consultar.

**Respuesta:**  
Un JSON con los datos de la moneda especificada.  

---
### Soluciones del ejercicio propuesto

Dado que el enunciado del challege meniona que en genral no se debe usar librerias cuando un modulo built-in lo puede resolver, se proponen dos soluciones:

A. **La primera solucion** solo usa las librerias de flask, pymongo y request. Por tanto, es necesario usar multiprocesingde Python para liberar la solicitud del usuario y permitir que el procesamiento se realice de forma as√≠ncrona.

B. **La segunda solucion** Esta soluci√≥n plantea el uso conjunto de Kafka y Apache Spark. Al publicar la petici√≥n en Kafka, el sistema responde de forma as√≠ncrona, liberando inmediatamente al usuario, mientras que el procesamiento de los datos se realiza en segundo plano. Gracias a la arquitectura distribuida de Apache Spark, basada en cl√∫steres, los mensajes pueden ser consumidos en paralelo, lo que permite leer, procesar, realizar peticiones HTTP y actualizar la base de datos de manera eficiente.

#### Solucion A:

#### üîó Diagrama de Componentes

En la siguiente imagen podemos observar un **diagrama de componentes**, junto con los **puertos y URLs** a trav√©s de los cuales cada componente se comunica entre s√≠, incluyendo la interacci√≥n del usuario:

![Component Diagram](./assets/component_diagram.png)

---

#### üîÑ Diagrama de Estados

En el siguiente diagrama se puede observar el **diagrama de estados** que el programa sigue para la separaci√≥n de responsabilidades. A continuaci√≥n, se describe el flujo del sistema:

1. **Estado 1 - `State_Init`**: Se encarga de recivir el archivo de texto fila por fila (**A**) y, cuando se acumula un batch de `x` filas (normalmente 50), se env√≠a dicho batch al estado 2, **`State_Cache`** (**B**).
2. **Estado 2 - `State_Cache`**: Revisa cu√°les de las `x` filas ya est√°n almacenadas en la base de datos usando consultas en modo bulk. Las que a√∫n no est√°n registradas en Mongo se env√≠an al estado **`State_Info`** (**C**).
3. **Estado 3 - `State_Info`**: Completa la informaci√≥n de cada fila haciendo un request al API de Mercado Libre (**G**).  
   - Si la informaci√≥n est√° completa, el registro se guarda en la colecci√≥n **`complete_register`**.  
   - Si falta alg√∫n dato o hay errores de respuesta, el registro se guarda en **`incomplete_register`** (**F**).  
   - Luego de procesar todo el batch, retorna al estado inicial **`State_Init`** para continuar con el siguiente grupo de filas (**D**) hasta completar todo el archivo (**A**).

![State Diagram](./assets/state_diagram.png)

#### Solucion B:

#### üîó Diagrama de Componentes

El siguiente diagrama de secuencia ilustra la comunicaci√≥n entre los distintos componentes del sistema durante un ciclo t√≠pico de solicitud‚Äìrespuesta. Se utiliza Apache Kafka como mecanismo de desacoplamiento para realizar procesamiento en segundo plano de forma eficiente.

![Component Diagram](./assets/component_with_broker.png)

**1. Usuario**  
Interact√∫a directamente con las interfaces expuestas v√≠a HTTP:
- `meli_api`
- `integration_api`
- `kafka_ui`
- `mongo-express`

**2. meli_api**  
Servicio que expone endpoints para consultar informaci√≥n de √≠tems.  
Es consumido por `consumer_api` durante el procesamiento de datos.

**3. integration_api**  
API que:
- Recibe solicitudes HTTP del usuario.
- Publica mensajes en Kafka para procesamiento as√≠ncrono.
- Devuelve inmediatamente una respuesta HTTP 200.


**4. kafka_broker**  
Sistema de mensajer√≠a basado en el patr√≥n **Pub/Sub (Publicaci√≥n/Suscripci√≥n)**:
- `integration_api` act√∫a como *producer* (publicador).
- `consumer_api` act√∫a como *consumer* (suscriptor).
- Kafka garantiza desacoplamiento, escalabilidad y procesamiento en paralelo.

**5. consumer_api**  
Servicio que:
- Escucha mensajes de Kafka.
- Lee un archivo externo para complementar y procesar datos usando apache kafka.

**6. kafka_ui**  
Interfaz gr√°fica para la administraci√≥n de Kafka:
- Visualizaci√≥n de t√≥picos, productores y consumidores.
- Inspecci√≥n en tiempo real de mensajes y flujo de datos.

**7. mongo-express**  
Dashboard visual accesible por navegador que permite:
- Navegar, consultar y administrar documentos dentro de MongoDB.
- √ötil para debugging y monitoreo de datos persistidos.

**8. MongoDB**  
Base de datos NoSQL documental:
- Almacena los datos finales procesados por `consumer_api`.
- Permite operaciones de lectura y escritura eficientes en formato JSON-like.

#### üîÑ Diagrama de Secuencia

En este diagrama podemos observar el **diagrama de secuencia** que el programa sigue para ejecutar el proceso completo. A continuacion se describe el flujo del sistema:

![Component Diagram](./assets/sequence_diagram.png)

1. **Recepci√≥n de la Solicitud HTTP**  
   El **Usuario** inicia la interacci√≥n enviando una solicitud HTTP al servicio `integration_api`.

2. **Publicaci√≥n de un Mensaje en Kafka**  
   El servicio `integration_api`, al recibir la solicitud, **publica un mensaje** en un t√≥pico gestionado por el `kafka_broker`. Este mensaje contiene toda la informaci√≥n necesaria para que otro componente contin√∫e con el procesamiento.

3. **Respuesta Inmediata al Usuario**  
   `integration_api` devuelve una respuesta **HTTP 200 OK** al usuario. A partir de este punto, la l√≥gica pasa a ser responsabilidad del sistema de mensajer√≠a Kafka, **liberando el hilo de ejecuci√≥n original**.

4. **Consumo del Mensaje por `consumer_api`**  
   El servicio `consumer_api`, suscrito al t√≥pico de Kafka, **consume el mensaje** tan pronto como est√© disponible.

5. **Lectura de Archivo Externo**  
   Despu√©s de consumir el mensaje, `consumer_api` accede a un **archivo local** (por ejemplo, CSV o JSON) para obtener datos adicionales necesarios para el procesamiento.

6. **Consultas a `meli_api` por cada √çtem**  
    Por cada elemento procesado, consumer_api realiza tres solicitudes HTTP independientes a meli_api:
    - Una solicitud para obtener la informaci√≥n del √≠tem.
    - Una solicitud para determinar la categor√≠a del √≠tem.
    - Una solicitud para obtener la informaci√≥n de la moneda.
    Estas operaciones se realizan en un bucle, asegurando que los tres tipos de datos se recojan para cada √≠tem antes de continuar.

7. **Persistencia de Datos en MongoDB**  
   Una vez recibidas todas las respuestas de `meli_api`, `consumer_api` realiza una √∫nica operaci√≥n de **guardado masivo** en la base de datos `mongo`.

**Para probar esta nueva soluci√≥n**, se puede realizar la siguiente petici√≥n donde el cuerpo del JSON es el mismo que se explic√≥ en la secci√≥n de **Probar las APIs**, pero con la ruta **/integration**.

```bash
POST: http://localhost:5001/integration
```

Body JSON:
```json
{
  "register_attributes": ["price", "name", "description"],
  "len_batch": 50,
  "name_file": "datalake.csv",
  "format": "csv",
  "separator": ",",
  "encoding": "utf-8"
}
```

### üöÄ Mejoras a implementar

En esta soluci√≥n se plantea leer los mensajes de Kafka a trav√©s de Apache Spark, lo cual depende del n√∫mero de particiones del t√≥pico para poder leer los mensajes de manera paralela. En este ejemplo, el t√≥pico se configur√≥ con 3 particiones. Otra forma de resolver el ejercicio es leer los mensajes de Kafka mediante la API de Kafka para Python y ejecutar un subproceso que realice el procesamiento requerido con PySpark. Esto permite que el consumidor no se quede ejecutando el proceso y pueda liberarse r√°pidamente para seguir escuchando Kafka. En ambas soluciones propuestas, se puede utilizar Kubernetes para escalar horizontalmente seg√∫n las r√©plicas configuradas.

Como implementaciones futuras para mejorar la soluci√≥n propuesta, se sugiere separar a√∫n m√°s las responsabilidades al leer el archivo, realizar las peticiones HTTP, completar los datos y actualizar la base de datos, tal como se hizo en la Soluci√≥n 1, donde se implement√≥ DDD y arquitectura hexagonal. Aunque ya se han utilizado m√©todos como mapPartitions, foreachPartition y map, al dividir a√∫n m√°s las responsabilidades, se podr√° aprovechar al m√°ximo estos m√©todos que ofrece PySpark, mejorando la paralelizaci√≥n y el rendimiento del procesamiento.

El archivo de entrada, que contiene la informaci√≥n de 'site' e 'id', se encuentra dentro del microservicio consumer_api. Por lo tanto, es necesario permitir que el usuario pueda subir este archivo, ya sea que se ubique de forma local o en la nube. Es importante mover este archivo a una ubicaci√≥n accesible para que consumer_api pueda leerlo.

Como mejora futura, se puede evaluar integrar un sistema de orquestaci√≥n de tareas como Celery, en conjunto con Redis como broker de mensajes, para desacoplar la l√≥gica de escritura en la base de datos del procesamiento principal. Esta arquitectura permitir√≠a reducir la carga sobre la BBDD, controlar mejor la concurrencia y gestionar los reintentos de forma m√°s robusta. Adem√°s, facilitar√≠a escalar de manera independiente las tareas de persistencia, especialmente cuando se utiliza un motor de procesamiento distribuido como Apache Spark, permitiendo as√≠ una mayor eficiencia y resiliencia en entornos de alto volumen de datos.

Una de las restricciones del proyecto era utilizar Flask; sin embargo, en el microservicio meli_api se propone el uso de FastAPI para reemplazar la librer√≠a requests por httpx, lo que permite aprovechar el modelo asincr√≥nico mediante async/await. Esto es posible porque FastAPI se basa en el est√°ndar ASGI, el cual habilita el uso de corrutinas y facilita un manejo m√°s eficiente de las solicitudes HTTP concurrentes.

---

### ‚öôÔ∏è Arquitectura y Dise√±o

El c√≥digo del desaf√≠o fue implementado 100% con **Programaci√≥n Orientada a Objetos (POO)** y, para modelar el flujo anterior, se utiliz√≥ el **patr√≥n de dise√±o de estado**.

Adem√°s, se siguieron los principios **SOLID**, se aplic√≥ una **arquitectura hexagonal**, **Domain-Driven Design (DDD)** y **vertical slicing**, con el fin de garantizar **flexibilidad, extensibilidad y mantenibilidad** del sistema.

Cada _feature_ posee su propia estructura con carpetas `application`, `domain` e `infrastructure`. Esto permite, por ejemplo, cambiar la base de datos o el endpoint del API de Mercado Libre sin modificar la l√≥gica de negocio, ya que el **caso de uso est√° desacoplado de los recursos externos**.

---

### üìÅ Estructura del C√≥digo

- La implementaci√≥n de los tres estados `State_Init`, `State_Cache` y `State_Info`, que corresponden a los casos de uso de negocio, se encuentra en la carpeta appliacion:  
  `./integration_api/fetch_integrate/application/pipeline_state.py`

- La conexi√≥n a los recursos externos (`open_file`, `database`, `request`) est√° ubicada en la carpeta infraestructura:  
  `./integration_api/fetch_integrate/infraestructure/integration_connection.py`

- La carpeta de dominio contiene constantes, par√°metros de entrada, interfaces abstractas, el archivo de texto y el contexto de los estados, que act√∫a como patr√≥n mediador.  `./integration_api/fetch_integrate/domain`

- Adicionalmente, se implement√≥ el patr√≥n *Facade*, que funciona como la interfaz mediante la cual el usuario puede realizar diferentes consultas HTTP.  
  Es importante mencionar que tanto `app.py` como `main.py` hacen uso de esta interfaz *Facade* ubicada en `integration_api\modules\fetch_integrate\infraestructure\integration_facade`.  
  Sin embargo, `app.py` corresponde a la aplicaci√≥n Flask, mientras que `main.py` permite ejecutar el programa como si fuera un script, sin necesidad de un framework web.  
  Esto significa que, si se desea cambiar a FastAPI, la modificaci√≥n ser√≠a sencilla, ya que el caso de uso no est√° acoplado a Flask ni a ning√∫n otro framework.

- Por √∫ltimo, se incluye un archivo adicional llamado `docker-compose.debug.yaml`, el cual ejecuta √∫nicamente los servicios `meli_app`, `mongo` y `mongo_express`.  
  En este entorno, es posible correr `main.py` (ubicado en `integration_api/main.py`) directamente para ejecutar el programa, de forma similar a c√≥mo lo har√≠a Flask.

  Incluso si se est√° utilizando el archivo `docker-compose.yaml` principal, se puede seguir ejecutando `main.py` desde el modo *debug* de VSCode.  
  Para esto, solo es necesario instalar las librer√≠as `pymongo` y `requests` en un entorno virtual de desarrollo, con los siguientes pasos:

  ```bash
  python -m venv venv
  source venv/bin/activate  # o venv\Scripts\activate en Windows
  pip install pymongo requests
  ```

  Esto facilita considerablemente el desarrollo, ya que evita la necesidad de subir y bajar constantemente el contenedor `integration_api`, o mantenerlo activo en segundo plano, lo que consumir√≠a m√°s recursos de RAM del equipo.

  Por √∫ltimo, si ejecuta primero `docker-compose.debug.yaml` y luego `docker-compose.yaml`, no olvide eliminar los contenedores anteriores con:

  ```bash
  docker rm meli_api integration_db
   ```
---
# üìò Desaf√≠o Te√≥rico

## 1. Procesos, hilos y corrutinas

### ‚óè Un caso en el que usar√≠as procesos para resolver un problema y por qu√©

Usar√≠a procesos cuando es necesaria la ejecuci√≥n de tareas que consumen muchos recursos de CPU pero que pueden ejecutarse en paralelo, como el procesamiento de im√°genes o los c√°lculos matem√°ticos pesados. La principal ventaja es que cada proceso tiene su propio espacio de memoria, lo cual permite evitar conflictos, aunque tambi√©n hace m√°s dif√≠cil compartir datos entre ellos. Aun as√≠, permite aprovechar m√∫ltiples n√∫cleos del procesador. En consecuencia, si un proceso falla, no afecta directamente a los dem√°s, lo que proporciona mayor robustez en tareas intensivas.

### ‚óè Un caso en el que usar√≠as threads para resolver un problema y por qu√©

Usar√≠a hilos principalmente cuando estoy trabajando con operaciones de entrada/salida o tareas que requieren esperar por recursos externos, como llamadas a APIs, consultas a BBDD, manejar conexiones de red o lectura de archivos. A diferencia de los procesos, los hilos son m√°s ligeros y comparten el mismo espacio de memoria, lo que permite una comunicaci√≥n r√°pida entre ellos.

### ‚óè Un caso en el que usar√≠as corrutinas para resolver un problema y por qu√©

Usar√≠a corrutinas cuando necesito manejar muchas tareas concurrentes que dependen de operaciones as√≠ncronas, como hacer miles de solicitudes a una API, interactuar con bases de datos en tiempo real o leer datos de manera secuencial sin bloquear el sistema. Las corrutinas permiten escribir c√≥digo as√≠ncrono de forma m√°s simple, consumen menos memoria que los hilos tradicionales y son ideales para aplicaciones donde la eficiencia y la escalabilidad en operaciones de entrada/salida (I/O) son importantes.

En el lenguaje de programaci√≥n Python, solo es posible ejecutar un hilo a la vez debido al GIL (Global Interpreter Lock), una restricci√≥n del int√©rprete CPython que evita la ejecuci√≥n simult√°nea de m√∫ltiples hilos en tareas CPU-bound. Esto se debe a c√≥mo Python maneja internamente la memoria y los objetos. Por esta raz√≥n, cuando se crean m√∫ltiples hilos, Python les asigna peque√±os fragmentos de tiempo de ejecuci√≥n de manera secuencial, dando la impresi√≥n de que se ejecutan en paralelo. Si se requiere una ejecuci√≥n real en paralelo es necesario utilizar el m√≥dulo multiprocessing, que crea procesos independientes con su propia memoria. Por otro lado, las corrutinas (async/await) en Python funcionan sobre un solo hilo, pero permiten continuar la ejecuci√≥n mientras se espera por una operaci√≥n I/O (como una consulta a una base de datos o una solicitud HTTP). Cuando una tarea necesita esperar, el control se cede a otra corrutina disponible, lo que mejora la eficiencia sin necesidad de m√∫ltiples hilos o procesos.

El multithreading en Python suele utilizarse para tareas I/O. Sin embargo, tambi√©n resulta √∫til en aplicaciones de rob√≥tica. Por ejemplo, lo he usado en peque√±os robots seguidores de l√≠nea con microprocesadores de un solo n√∫cleo y bater√≠as limitadas. En estos casos, Python permite crear m√∫ltiples hilos que ejecutan tareas breves, como la lectura de distintos sensores, de forma intercalada. Aunque solo un hilo se ejecuta a la vez, el cambio r√°pido entre ellos da la sensaci√≥n de que todos los sensores se est√°n leyendo simult√°neamente.

## 2. Optimizaci√≥n de recursos del sistema operativo

### ‚óè Si tuvieras 1.000.000 de elementos y tuvieras que consultar para cada uno de ellos informaci√≥n en una API HTTP. ¬øC√≥mo lo har√≠as? Explicar.

Lo har√≠a de forma concurrente y controlada, optimizando el uso de recursos y evitando sobrecargar la API. Para lograr esto, aplicar√≠a las siguientes estrategias:

- Usar√≠a corrutinas como async/await en Python para lanzar m√∫ltiples solicitudes HTTP de manera concurrente, aprovechando que las llamadas a APIs son operaciones de entrada/salida.
- Para evitar errores por exceso de peticiones, como el ‚Äú429 Too Many Requests‚Äù, implementar√≠a un sistema de rate limiting para limitar la cantidad de solicitudes simult√°neas y respetar los l√≠mites de la API.
- Si la API permite hacer peticiones por lotes (batch requests), agrupar√≠a varios elementos en una misma solicitud para reducir el n√∫mero total de llamadas.
- Incluir√≠a una l√≥gica de reintentos con backoff exponencial para gestionar fallos temporales o errores de red.
- Dada la cantidad de peticiones, implementar√≠a un sistema de colas como Kafka para lograr una mejor persistencia y recuperaci√≥n controlada. Adem√°s, almacenar√≠a las peticiones que no fueron respondidas exitosamente (despu√©s de cierto n√∫mero de reintentos con backoff exponencial) en Kafka o en una base de datos para reprocesarlas luego.
- Si el procesamiento de la respuesta de cada elemento se puede realizar de forma independiente, considerar√≠a el uso de multiprocesamiento para aprovechar m√∫ltiples n√∫cleos del procesador y distribuir la carga.
- Implementar√≠a un sistema de monitoreo para registrar m√©tricas clave como el tiempo de respuesta de la API, n√∫mero de reintentos, tasa de √©xito y de fallos. Esto permite detectar cuellos de botella o comportamientos an√≥malos inesperados. Se puede implementar generando logs estructurados o utilizando herramientas como Prometheus o Grafana.
- Implementar√≠a una capa de cach√© para evitar llamadas innecesarias a la API en casos de elementos o respuestas repetitivas, reduciendo as√≠ la carga total del sistema.
- Podr√≠a distribuir la carga dividiendo el proceso en m√∫ltiples nodos o servicios distribuidos, utilizando herramientas como Kubernetes para lograr escalabilidad horizontal y resiliencia.

## 3. An√°lisis de complejidad

### ‚óè Dados 4 algoritmos A, B, C y D que cumplen la misma funcionalidad, con complejidades O(n¬≤), O(n¬≥), O(2‚Åø) y O(n log n), respectivamente, ¬øCu√°l de los algoritmos favorecer√≠as y cu√°l descartar√≠as en principio? Explicar por qu√©.

Favorecer√≠a el algoritmo O(n log n) y descartar√≠a el algoritmo O(2‚Åø), dado que la complejidad algor√≠tmica nos da una estimaci√≥n del crecimiento del tiempo de ejecuci√≥n en funci√≥n del tama√±o de los datos de entrada (n).

- O(n¬≤) y O(n¬≥) pueden ser aceptables para entradas peque√±as, e incluso medianas, pero hay que tener en cuenta que su rendimiento se degrada con rapidez a medida que n crece, especialmente en el caso de la complejidad c√∫bica. El algoritmo burbuja tiene una complejidad en tiempo de O(n¬≤), y la multiplicaci√≥n de matrices con triple bucle tiene una complejidad en tiempo de O(n¬≥).
- O(2‚Åø) representa un crecimiento exponencial, lo que lo hace muy ineficiente incluso para valores peque√±os de n. Este tipo de algoritmo deber√≠a evitarse y reemplazarse por otro m√°s eficiente y optimizado. El algoritmo de Fibonacci recursivo sin memorizaci√≥n tiene esta complejidad en tiempo.
- O(n log n) es la complejidad m√°s eficiente entre las opciones dadas y es ideal para grandes vol√∫menes de datos, ya que escala de forma razonable. Algoritmos como Merge Sort o Heap Sort tienen esta complejidad en tiempo.

### ‚óè Asume que dispones de dos bases de datos para utilizar en diferentes problemas a resolver. La primera, llamada AlfaDB, tiene una complejidad de O(1) en consulta y O(n¬≤) en escritura. La segunda, llamada BetaDB, tiene una complejidad de O(log n) tanto para consulta como para escritura. Describe, en forma sucinta, qu√© casos de uso podr√≠as atacar con cada una.

- **AlfaDB**: usar√≠a esta base de datos en casos donde se realizan consultas muy frecuentes y escrituras poco frecuentes, dado que ofrece consultas en tiempo constante O(1). Esto la hace ideal para aplicaciones donde la velocidad de lectura es prioritaria y se puede tolerar un alto costo en las escrituras, como en sistemas de cach√© o bases de datos que almacenan configuraciones cr√≠ticas que rara vez cambian pero se consultan con frecuencia, por ejemplo, para reiniciar sistemas.

- **BetaDB**: la usar√≠a en situaciones donde se requiere un rendimiento equilibrado entre operaciones de lectura y escritura, ya que ambas tienen una complejidad de O(log n). Esto la hace adecuada para sistemas transaccionales (OLTP), plataformas con usuarios activos o aplicaciones en tiempo real que necesitan consistencia y eficiencia en ambas operaciones.